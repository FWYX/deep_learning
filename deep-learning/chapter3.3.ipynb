{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train = True):   #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.4429,  0.3087],\n",
       "         [ 0.6850,  0.2491],\n",
       "         [ 0.9798,  0.1723],\n",
       "         [ 0.4804, -1.1634],\n",
       "         [ 0.7851, -2.2130],\n",
       "         [ 1.2080,  0.0298],\n",
       "         [-0.6162,  2.0179],\n",
       "         [-1.2108,  0.6057],\n",
       "         [ 0.8505, -0.0848],\n",
       "         [ 0.4974,  0.2549]]),\n",
       " tensor([[ 0.2496],\n",
       "         [ 4.7297],\n",
       "         [ 5.5735],\n",
       "         [ 9.1153],\n",
       "         [13.2736],\n",
       "         [ 6.5073],\n",
       "         [-3.8909],\n",
       "         [-0.2799],\n",
       "         [ 6.1870],\n",
       "         [ 4.3324]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.0144, -0.0100]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)\n",
    "net[0].weight, net[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:0.000454\n",
      "epoch:2, loss:0.000094\n",
      "epoch:3, loss:0.000032\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(X), y)\n",
    "    print(f'epoch:{epoch+1}, loss:{l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的误差:tensor([ 2.6691e-04, -3.6001e-05])\n",
      "b的误差:tensor([0.0009])\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight.data\n",
    "print(f'w的误差:{true_w - w.reshape(true_w.shape)}')\n",
    "b = net[0].bias.data\n",
    "print(f'b的误差:{true_b - b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8675e-04, -1.3266e-05]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = nn.Sequential(nn.Linear(2, 1))\n",
    "net2 = nn.Sequential(nn.Linear(2, 1))\n",
    "net1[0].weight.data.normal_(0, 0.01)\n",
    "net1[0].bias.data.fill_(0)\n",
    "net2[0].weight.data.normal_(0, 0.01)\n",
    "net2[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = nn.MSELoss(reduction = 'mean') #默认是mean\n",
    "loss2 = nn.MSELoss(reduction = 'sum')\n",
    "trainer1 = torch.optim.SGD(net1.parameters(), lr = 0.03)\n",
    "trainer2 = torch.optim.SGD(net2.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\tloss1:0.000141\tloss2:0.001412\n",
      "\tnet1_w.grad: tensor([[-0.0079, -0.0131]]) \tnet1_b.grad: tensor([0.0074])\n",
      "\tnet2_w.grad: tensor([[-0.0787, -0.1307]]) \tnet2_b.grad: tensor([0.0744])\n",
      "epoch:2\tloss1:0.000138\tloss2:0.001383\n",
      "\tnet1_w.grad: tensor([[-0.0042, -0.0062]]) \tnet1_b.grad: tensor([-0.0098])\n",
      "\tnet2_w.grad: tensor([[-0.0425, -0.0622]]) \tnet2_b.grad: tensor([-0.0984])\n",
      "epoch:3\tloss1:0.000125\tloss2:0.001249\n",
      "\tnet1_w.grad: tensor([[-0.0066, -0.0040]]) \tnet1_b.grad: tensor([0.0065])\n",
      "\tnet2_w.grad: tensor([[-0.0659, -0.0395]]) \tnet2_b.grad: tensor([0.0648])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l1 = loss1(net1(X), y)\n",
    "        l2 = loss2(net2(X), y)\n",
    "        trainer1.zero_grad()\n",
    "        trainer2.zero_grad()\n",
    "        l1.backward()\n",
    "        l2.backward()\n",
    "        trainer1.step()\n",
    "        trainer2.step()\n",
    "        trainer1.step()\n",
    "        trainer2.step()\n",
    "    print(f'epoch:{epoch+1}\\tloss1:{l1:f}\\tloss2:{l2:f}')\n",
    "    print('\\tnet1_w.grad:', net1[0].weight.grad, '\\tnet1_b.grad:', net1[0].bias.grad)\n",
    "    print('\\tnet2_w.grad:', net2[0].weight.grad, '\\tnet2_b.grad:', net2[0].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1的w的误差tensor([-0.0012,  0.0019])\n",
      "net2的w的误差tensor([-0.0012,  0.0019])\n",
      "net1的b的误差tensor([0.0004])\n",
      "net1的b的误差tensor([0.0004])\n"
     ]
    }
   ],
   "source": [
    "print(f'net1的w的误差{true_w - net1[0].weight.data.reshape(true_w.shape)}')\n",
    "print(f'net2的w的误差{true_w - net2[0].weight.data.reshape(true_w.shape)}')\n",
    "print(f'net1的b的误差{true_b - net1[0].bias.data}')\n",
    "print(f'net1的b的误差{true_b - net1[0].bias.data}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e4f9e2b429d5082852bebba048ae59313251508f681ce2db91105e3803a5035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
